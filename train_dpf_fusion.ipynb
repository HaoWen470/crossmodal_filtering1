{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0 1.18.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "import fannypack\n",
    "from lib import dpf, panda_models, panda_datasets, panda_training, fusion_pf, fusion, omnipush_datasets\n",
    "\n",
    "print(torch.__version__, np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment configuration\n",
    "experiment_name = \"pf_fusion_64u\"\n",
    "dataset_args = {\n",
    "    'use_proprioception': True,\n",
    "    'use_haptics': True,\n",
    "    'use_vision': True,\n",
    "    'vision_interval': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed data: 176075 active, 62925 inactive\n",
      "Keeping: 62925\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4989fd7669ca426cb81831e98f115b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 240000 points\n",
      "Parsed data: 13331 active, 1669 inactive\n",
      "Keeping (inactive): 1669\n"
     ]
    }
   ],
   "source": [
    "# dynamics_trainset = omnipush_datasets.OmnipushDynamicsDataset(\n",
    "#     \"omnipush_data/ellip1_trainset.hdf5\",\n",
    "#     \"omnipush_data/ellip2_trainset.hdf5\",\n",
    "#     \"omnipush_data/ellip3_trainset.hdf5\",\n",
    "#     **dataset_args\n",
    "# )\n",
    "# dynamics_recurrent_trainset = omnipush_datasets.OmnipushSubsequenceDataset(\n",
    "#     \"omnipush_data/ellip1_trainset.hdf5\",\n",
    "#     \"omnipush_data/ellip2_trainset.hdf5\",\n",
    "#     \"omnipush_data/ellip3_trainset.hdf5\",\n",
    "#     subsequence_length=16,\n",
    "#     **dataset_args\n",
    "# )\n",
    "# measurement_trainset = omnipush_datasets.OmnipushMeasurementDataset(\n",
    "#     \"omnipush_data/ellip1_trainset.hdf5\",\n",
    "#     \"omnipush_data/ellip2_trainset.hdf5\",\n",
    "#     \"omnipush_data/ellip3_trainset.hdf5\",\n",
    "#     samples_per_pair=10,\n",
    "#     **dataset_args\n",
    "# )\n",
    "# e2e_trainset = omnipush_datasets.OmnipushParticleFilterDataset(\n",
    "#     \"omnipush_data/ellip1_trainset.hdf5\",\n",
    "#     \"omnipush_data/ellip2_trainset.hdf5\",\n",
    "#     \"omnipush_data/ellip3_trainset.hdf5\",\n",
    "#     subsequence_length=16,\n",
    "#     particle_count=30,\n",
    "#     particle_stddev=(.1, .1),\n",
    "#     **dataset_args\n",
    "# )\n",
    "# eval_trajectories = omnipush_datasets.load_trajectories(\n",
    "#     (\"omnipush_data/ellip1_trainset.hdf5\", 10),\n",
    "# #     \"omnipush_data/ellip2_testset.hdf5\",\n",
    "# #     \"omnipush_data/ellip3_testset.hdf5\",\n",
    "#     **dataset_args\n",
    "# )\n",
    "dynamics_trainset = panda_datasets.PandaDynamicsDataset(\n",
    "    \"data/gentle_push_1000.hdf5\",\n",
    "    **dataset_args\n",
    ")\n",
    "dynamics_recurrent_trainset = panda_datasets.PandaSubsequenceDataset(\n",
    "    \"data/gentle_push_1000.hdf5\",\n",
    "    subsequence_length=16,\n",
    "    **dataset_args\n",
    ")\n",
    "measurement_trainset = panda_datasets.PandaMeasurementDataset(\n",
    "    \"data/gentle_push_1000.hdf5\",\n",
    "    samples_per_pair=10,\n",
    "    **dataset_args\n",
    ")\n",
    "e2e_trainset = panda_datasets.PandaParticleFilterDataset(\n",
    "    \"data/gentle_push_1000.hdf5\",\n",
    "    subsequence_length=16,\n",
    "    particle_count=30,\n",
    "    particle_stddev=(.1, .1),\n",
    "    **dataset_args\n",
    ")\n",
    "eval_trajectories = panda_datasets.load_trajectories(\n",
    "    \"data/gentle_push_10.hdf5\",\n",
    "    **dataset_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[buddy-pf_fusion_64u] Using device: cuda\n",
      "[buddy-pf_fusion_64u] Loaded metadata: {'use_haptics': True, 'use_proprioception': True, 'use_vision': True, 'vision_interval': 2}\n",
      "[buddy-pf_fusion_64u] Read checkpoint from path: checkpoints/pf_fusion_64u-0000000000005714.ckpt\n",
      "[buddy-pf_fusion_64u] Loaded checkpoint at step: 5714\n",
      "[buddy-pf_fusion_64u] Wrote metadata to: metadata/pf_fusion_64u.yaml\n"
     ]
    }
   ],
   "source": [
    "# Create models & training buddy\n",
    "\n",
    "pf_image_model = panda_models.PandaParticleFilterNetwork(\n",
    "    panda_models.PandaDynamicsModel(),\n",
    "    panda_models.PandaMeasurementModel(units=64, missing_modalities=['gripper_force']),\n",
    ")\n",
    "\n",
    "pf_force_model = panda_models.PandaParticleFilterNetwork(\n",
    "    panda_models.PandaDynamicsModel(),\n",
    "    panda_models.PandaMeasurementModel(units=64, missing_modalities=['image']),\n",
    ")\n",
    "\n",
    "weight_model = fusion.CrossModalWeights(state_dim=1)\n",
    "\n",
    "pf_fusion_model = fusion_pf.ParticleFusionModel(\n",
    "    pf_image_model,\n",
    "    pf_force_model,\n",
    "    weight_model\n",
    ")\n",
    "\n",
    "buddy = fannypack.utils.Buddy(\n",
    "    experiment_name,\n",
    "    pf_fusion_model,\n",
    "    optimizer_names=[\n",
    "        \"e2e_fusion\",\n",
    "        \"e2e_image\",\n",
    "        \"e2e_force\",\n",
    "        \"dynamics_image\",\n",
    "        \"dynamics_force\",\n",
    "        \"dynamics_recurrent_image\",\n",
    "        \"dynamics_recurrent_force\",\n",
    "        \"measurement_image\",\n",
    "        \"measurement_force\",\n",
    "    ]\n",
    ")\n",
    "buddy.add_metadata(dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[buddy-pf_fusion_64u] Skipping redundant checkpoint save\n"
     ]
    }
   ],
   "source": [
    "# buddy.load_checkpoint(\"phase_3_trained_e2e_unfreezedimageforce\")\n",
    "buddy.save_checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamics pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e4227b315549d7b164212aba49c6b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7469), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[buddy-pf_fusion_64u] Saved checkpoint to path: checkpoints/pf_fusion_64u-0000000000010000.ckpt\n",
      "\n",
      "Epoch loss: 0.002210499\n",
      "\n",
      "Training epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1bd363100e44feca94b0df9b3ca6f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7469), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[buddy-pf_fusion_64u] Saved checkpoint to path: checkpoints/pf_fusion_64u-0000000000020000.ckpt\n",
      "\n",
      "Epoch loss: 0.0019166376\n",
      "\n",
      "Training epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e13aa3c9d3147b1b504b6c1af052472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7469), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch loss: 0.0018186115\n",
      "\n",
      "[buddy-pf_fusion_64u] Saved checkpoint to path: checkpoints/pf_fusion_64u-0000000000028121.ckpt\n",
      "[buddy-pf_fusion_64u] Read checkpoint from path: checkpoints/pf_fusion_64u-0000000000028121.ckpt\n",
      "[buddy-pf_fusion_64u] Loaded module: image_model.dynamics_model => force_model.dynamics_model\n",
      "[buddy-pf_fusion_64u] Saved checkpoint to path: checkpoints/pf_fusion_64u-phase_0_dynamics_pretrain.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Dynamics pre-training! (non-recurrent)\n",
    "models = [\n",
    "    (pf_image_model, 'dynamics_image'),\n",
    "#     (pf_force_model, 'dynamics_force'),\n",
    "]\n",
    "dataloader = torch.utils.data.DataLoader(dynamics_trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "for pf_model, optim_name in models:\n",
    "    for i in range(3):\n",
    "        print(\"Training epoch\", i)\n",
    "        panda_training.train_dynamics(buddy, pf_model, dataloader, log_interval=1, optim_name=optim_name)\n",
    "        print()\n",
    "\n",
    "buddy.save_checkpoint()\n",
    "# Our dynamics models are the same for now, so we can just copy the parameters over\n",
    "buddy.load_checkpoint_module(source='image_model.dynamics_model', target='force_model.dynamics_model')\n",
    "\n",
    "buddy.save_checkpoint(\"phase_0_dynamics_pretrain\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5ced3d9ac94499b0bcd2d015b6e3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=469), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch loss: 0.0017725625\n",
      "Training epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bceceffe9f634c899733f1b0cbcdf650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=469), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch loss: 0.00073924236\n",
      "Training epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d2bf8984604523ac3e31468e5a1cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=469), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch loss: 0.0005212756\n",
      "[buddy-pf_fusion_64u] Saved checkpoint to path: checkpoints/pf_fusion_64u-0000000000029528.ckpt\n",
      "[buddy-pf_fusion_64u] Read checkpoint from path: checkpoints/pf_fusion_64u-0000000000029528.ckpt\n",
      "[buddy-pf_fusion_64u] Loaded module: image_model.dynamics_model => force_model.dynamics_model\n",
      "[buddy-pf_fusion_64u] Saved checkpoint to path: checkpoints/pf_fusion_64u-phase_1_dynamics_pretrain_recurrent.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Dynamics pre-training! (recurrent)\n",
    "models = [\n",
    "    (pf_image_model, 'dynamics_recurrent_image'),\n",
    "#     (pf_force_model, 'dynamics_recurrent_force'),\n",
    "]\n",
    "dataloader = torch.utils.data.DataLoader(dynamics_recurrent_trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "for pf_model, optim_name in models:\n",
    "    for i in range(3):\n",
    "        print(\"Training epoch\", i)\n",
    "        panda_training.train_dynamics_recurrent(buddy, pf_model, dataloader, log_interval=1, loss_type='l2', optim_name=optim_name)\n",
    "\n",
    "buddy.save_checkpoint()\n",
    "# Our dynamics models are the same for now, so we can just copy the parameters over\n",
    "buddy.load_checkpoint_module(source='image_model.dynamics_model', target='force_model.dynamics_model')\n",
    "\n",
    "buddy.save_checkpoint(\"phase_1_dynamics_pretrain_recurrent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measurement pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed9f36f6d564fd6aaf08cdb0f8af7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=75000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[buddy-pf_fusion_64u] Saved checkpoint to path: checkpoints/pf_fusion_64u-0000000000030000.ckpt\n",
      "[buddy-pf_fusion_64u] Saved checkpoint to path: checkpoints/pf_fusion_64u-0000000000040000.ckpt\n",
      "[buddy-pf_fusion_64u] Saved checkpoint to path: checkpoints/pf_fusion_64u-0000000000050000.ckpt\n",
      "[buddy-pf_fusion_64u] Saved checkpoint to path: checkpoints/pf_fusion_64u-0000000000060000.ckpt\n",
      "[buddy-pf_fusion_64u] Saved checkpoint to path: checkpoints/pf_fusion_64u-0000000000070000.ckpt\n",
      "[buddy-pf_fusion_64u] Saved checkpoint to path: checkpoints/pf_fusion_64u-0000000000080000.ckpt\n",
      "[buddy-pf_fusion_64u] Saved checkpoint to path: checkpoints/pf_fusion_64u-0000000000090000.ckpt\n",
      "[buddy-pf_fusion_64u] Saved checkpoint to path: checkpoints/pf_fusion_64u-0000000000100000.ckpt\n",
      "\n",
      "Epoch loss: 53.43981\n",
      "Training epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96e6188428e4747a903270925b5491b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=75000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [\n",
    "    (pf_image_model, 'measurement_image'),\n",
    "    (pf_force_model, 'measurement_force'),\n",
    "]\n",
    "measurement_trainset_loader = torch.utils.data.DataLoader(\n",
    "    measurement_trainset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=16)\n",
    "for pf_model, optim_name in models:\n",
    "    for i in range(1):\n",
    "        print(\"Training epoch\", i)\n",
    "        panda_training.train_measurement(buddy, pf_model, measurement_trainset_loader, log_interval=20, optim_name=optim_name)\n",
    "\n",
    "buddy.save_checkpoint(\"phase_2_measurement_pretrain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end training (individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (pf_image_model, 'e2e_image'),\n",
    "    (pf_force_model, 'e2e_force'),\n",
    "]\n",
    "for pf_model, optim_name in models:\n",
    "    pf_model.freeze_measurement_model = False\n",
    "    pf_model.freeze_dynamics_model = True\n",
    "    e2e_trainset_loader = torch.utils.data.DataLoader(e2e_trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "    for i in range(5):\n",
    "        print(\"Training epoch\", i)\n",
    "        panda_training.train_e2e(buddy, pf_model, e2e_trainset_loader, loss_type=\"mse\", optim_name=optim_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end training (fusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_name = \"e2e_fusion\"\n",
    "pf_model = pf_fusion_model\n",
    "pf_model.freeze_image_model = False\n",
    "pf_model.freeze_force_model = False\n",
    "# pf_model.image_model.freeze_dynamics_model = False\n",
    "# pf_model.force_model.freeze_dynamics_model = False\n",
    "e2e_trainset_loader = torch.utils.data.DataLoader(e2e_trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "for i in range(5):\n",
    "    print(\"Training epoch\", i)\n",
    "    panda_training.train_e2e(buddy, pf_model, e2e_trainset_loader, loss_type=\"mse\", optim_name=optim_name)\n",
    "buddy.save_checkpoint(\"phase_3_trained_e2e_unfreezedimageforce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phases = [\n",
    "#     'phase_0_dynamics_pretrain',\n",
    "#     'phase_1_dynamics_pretrain_recurrent',\n",
    "#     'phase_2_measurement_pretrain',\n",
    "#     'phase_3_trained_e2e'\n",
    "]   \n",
    "# pf_fusion_model.image_model.dynamics_model.state_noise_stddev = (0.01, 0.01)\n",
    "# pf_fusion_model.force_model.dynamics_model.state_noise_stddev = (0.01, 0.01)\n",
    "eval_trajectories = omnipush_datasets.load_trajectories(\n",
    "    (\"omnipush_data/ellip1_trainset.hdf5\", 10),\n",
    "#     \"omnipush_data/ellip2_testset.hdf5\",\n",
    "#     \"omnipush_data/ellip3_testset.hdf5\",\n",
    "    **dataset_args\n",
    ")\n",
    "\n",
    "pf_model = pf_image_model\n",
    "# for phase in phases:\n",
    "#     buddy.load_checkpoint(phase)\n",
    "#     print(phase)\n",
    "pred, actual = panda_training.rollout(pf_model, eval_trajectories, start_time=0, max_timesteps=1000, particle_count=200, noisy_dynamics=True)\n",
    "panda_training.eval_rollout(pred, actual, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pf_model.image_model\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
